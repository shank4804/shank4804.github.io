<!doctype html>

<html lang="en" class="h-100">
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="generator" content="Hugo 0.75.1" />
  <link rel="stylesheet" href="https://shank4804.github.io/css/bootstrap.min.css">
  
  
  <title> | Shashank&#39;s Website</title>
  <style>
.container {
  max-width: 700px;
}
#nav a {
  font-weight: bold;
  color: inherit;
}
#nav a.nav-link-active {
  background-color: #212529;
  color: #fff;
}
#nav-border {
  border-bottom: 1px solid #212529;
}
#main {
  margin-top: 1em;
  margin-bottom: 4em;
}
#home-jumbotron {
  background-color: inherit;
}
#footer .container {
  padding: 1em 0;
}
#footer a {
  color: inherit;
  text-decoration: underline;
}
.font-125 {
  font-size: 125%;
}
.tag-btn {
  margin-bottom: 0.3em;
}
pre {
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  padding: 16px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  background-color: transparent;
  border-radius: 0;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 4px;
}
img,
iframe,
embed,
video,
audio {
  max-width: 100%;
}
</style>
</head>
  <body class="d-flex flex-column h-100">
    <div id="nav-border" class="container">
  <nav id="nav" class="nav justify-content-center">
  
  
  
    
    
      
      
      
      
        
      
    
    
    <a class="nav-link " href="/"><i data-feather="home"></i> About</a>
  
    
    
      
      
      
      
        
      
    
    
    <a class="nav-link " href="/posts/"><i data-feather="edit"></i> Blog</a>
  
    
    
      
      
      
      
        
      
    
    
    <a class="nav-link " href="/photography"><i data-feather="camera"></i> Photography</a>
  
    
    
      
      
      
      
        
      
    
    
    <a class="nav-link " href="/resume"><i data-feather="file-text"></i> Resume</a>
  
    
    
      
      
      
      
        
      
    
    
    <a class="nav-link " href="/contact"><i data-feather="send"></i> Contact</a>
  
  </nav>
</div>
    <div class="container">
      <main id="main">
        

<h1></h1>
<p>Title: Beyond &ldquo;Vibe Coding&rdquo;: How I Built a Multi-LLM Debate Platform with Opus 4.5</p>
<p>I kept running into the same frustration: every LLM has blind spots. Ask GPT a question, you get GPT&rsquo;s particular style and biases. Same with Claude, same with Gemini. I wanted a tool where I could ask all three the same question simultaneously and watch them debate each other‚Äîlike a group chat where AI models challenge each other&rsquo;s reasoning.</p>
<p>I didn&rsquo;t just want to solve this problem. I wanted to test whether the new AI-assisted development workflow actually works for PMs. Can we really go from idea to working prototype without a large team?</p>
<p>So I built AI Trio (<a href="https://ai-trio.cloud">https://ai-trio.cloud</a>) to answer both questions.
Spoiler: The answer to the second question is &ldquo;yes, but&hellip;&rdquo; and that &ldquo;but&rdquo; is where things get interesting.</p>
<p>The New Reality: From PRD to Prototype in Hours
My workflow was deliberately AI-driven with human in the loop:</p>
<p>Ideate a feature with ChatGPT
Write high-level requirements, asking ChatGPT to generate a clear PRD
Feed the PRD to Claude Code with Opus 4.5
Review, test, iterate</p>
<p>Results: ~95% of specified features worked on first generation. UI styling often exceeded my vision.
But here&rsquo;s what &ldquo;95%&rdquo; hides:</p>
<p>Edge cases weren&rsquo;t in my PRD, so they weren&rsquo;t in the code
Security considerations required explicit specification
Architecture was sound only because I designed it‚Äîthe AI executed, it didn&rsquo;t architect</p>
<p>The real shift: The bottleneck has moved from &ldquo;writing syntax&rdquo; to &ldquo;specifying requirements completely.&rdquo; If you can write a comprehensive PRD that anticipates edge cases and scale, you can ship remarkably fast. But that &ldquo;if&rdquo; is doing heavy lifting.
What I Actually Built
The original pain point was simple: single LLM interactions suffer from that model&rsquo;s particular blind spots and biases. I wanted three leading models (GPT-5, Gemini, Claude) to debate the same question simultaneously‚Äîlike a group chat where they can see each other&rsquo;s answers.
Core Features:</p>
<p>Multi-Model Streaming: Real-time responses from three models simultaneously, each aware of the others
Voice Room: Talk to all three models at once‚Äîlike a conference call with AI
Context-Aware Web Search: Automatic web search when models detect they need current information
Comparison Mode: Side-by-side evaluation of responses and reasoning styles
Multi-Layer Safety: Defense-in-depth approach with prompt injection detection, output validation, and rate limiting</p>
<p>What Still Required Human Judgment:</p>
<p>Deployment configuration and CI/CD pipelines
Cost monitoring and optimization
Security architecture design</p>
<p>These aren&rsquo;t minor details‚Äîthey&rsquo;re the difference between a demo and a production app. AI accelerated the 80%, but the final 20% still required expertise.
The Unexpected Product Insight: Disagreement as a Feature
Early user feedback revealed something surprising: the value wasn&rsquo;t just getting multiple perspectives‚Äîit was seeing where and why models diverged.
For simple questions (&ldquo;What&rsquo;s the capital of France?&quot;), three identical answers just added noise. But for ambiguous decisions (&ldquo;Should I buy or lease a car?&quot;), watching models emphasize different tradeoffs (cost vs. flexibility, short-term vs. long-term) exposed the assumptions hidden in each response.
The caveat: This only works when users can evaluate the disagreement. For highly technical questions outside their expertise, three conflicting answers create decision paralysis, not clarity.
Key learning: Multi-model debates expose tradeoffs and assumptions‚Äîthey&rsquo;re a &ldquo;second opinion generator,&rdquo; not a replacement for expertise.</p>
<p>The economics tension: Pricing predictability is hard
Building this surfaced a core pricing tradeoff in AI products: pay-per-token is fair, but it‚Äôs not predictable. I kept second-guessing product decisions like, ‚ÄúShould I enable web search?‚Äù or ‚ÄúWhat if someone spams it and my costs explode?‚Äù</p>
<p>With a 10-messages/day per user limit, ~500 tokens per request/response, and three models queried per message, I estimated about $0.01 to $0.03 per user query (depending on the model mix). At max usage (roughly 300 queries/month), that‚Äôs $3 to $9 per user per month in API costs alone. The catch: token usage is hard to police. One detailed question that triggers a long answer can easily push costs to 3x the baseline.</p>
<p>That experience convinced me a hybrid pricing model is the right default for most AI products:</p>
<ul>
<li>A base tier with included usage (a predictable floor)</li>
<li>Usage-based pricing after the included amount (fair scaling)</li>
<li>User-set spending caps (reduces ‚Äúbill shock‚Äù anxiety)</li>
</ul>
<p>Stripe‚Äôs write-up on AI pricing strategies articulates this hybrid approach clearly: <a href="https://stripe.com/resources/more/pricing-strategies-for-ai-companies">https://stripe.com/resources/more/pricing-strategies-for-ai-companies</a></p>
<p>The Takeaway
The barrier to validating product ideas has collapsed. PMs who can write clear requirements can now build functional prototypes in days, not weeks.</p>
<p>But the prototype is just the beginning. AI ships exactly what you specify and quietly skips what you don‚Äôt, so productization still depends on human judgment (for now üôÇ) around security, scale, reliability, and UX.</p>
<p>The tools have changed. The hard problems haven‚Äôt so far, they‚Äôve just shifted from ‚Äúcan we build it?‚Äù to ‚Äúcan we trust it enough to run and ship?‚Äù</p>
<p>Check out AI Trio: <a href="https://ai-trio.cloud">https://ai-trio.cloud</a>
(Personal side project built for learning purposes)</p>



      </main>
    </div>
    
<footer id="footer" class="mt-auto text-center text-muted">
  <div class="container">
    Made with <a href="https://gohugo.io/">Hugo</a> and Golang
  </div>
</footer>

    <script src="https://shank4804.github.io/js/feather.min.js"></script>
<script>
  feather.replace()
</script>


    
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-27970776-2', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  </body>
</html>